
%\section{Algorithms}
\section{Clustering algorithms}
\subsection{Deterministic case}
\begin{algorithm}
\label{alg:DetClustering}
  \caption{Clustering the steady state deterministic simulation results}
 \begin{algorithmic}[1]
    \Statex
      \For{each data point}
      	\If{first point}
      		\State Make first cluster
      		\State cluster counter = 1
      	\Else
      		\For{each cluster}
      			\If{cluster within cluster means $\pm$ delta}      			
      					\State Add to existing cluster
      					\State Update means of clusters
      			\EndIf
      			\If{reached\_end and not assigned to cluster}
      				\State cluster counter +=  1
      				\State Add new cluster
      			\EndIf
      		\EndFor
      	\EndIf
      \EndFor
  \end{algorithmic}
\end{algorithm}


\subsection{Stochastic case}
\paragraph{Gap statistic}
\begin{algorithm}
\label{alg:GapStatistic}
\caption{Choosing the optimal number of clusters}
 \begin{algorithmic}[1]
    \Statex
    \Function{Wk}{clusters, cluster\_centres}
    	\For{each cluster}
    		\For{each point in cluster}
    			\State a = matrix norm (cluster\_centre $-$ point)
    		\EndFor
    		\State $dk = \sum((a)^2 )\times (2 \times $ number of points in cluster)
    	\EndFor
    	\State $wk = \frac{ \sum(dk)}{2 \times (number of points in cluster)}$
    	\State \Return wk
    \EndFunction
    %\Statex  
    %\Function{bounding\_box}{data}
    %	\State $xmin, xmax = $ min and max of x axis in data
    %	\State $ymin, ymax = $ min and max of y axis in data
    %	\State \Return $((xmin, xmax), (ymin, ymax)) $
    %\EndFunction
    
    \Statex
    \Function{Gap\_statistic}{data, cutoff}
    	%\State $(xmin, xmax), (ymin, ymax)$ = \Call{bounding\_box}{data}
    	 	\State ks = [1,2,3,4]
    	\For{k in ks}
   			\State cluster\_centres, clusters = \Call{Kmeans}{data, k, cutoff}
   			\State $Wk = \log$(\Call{Wk}{clusters, cluster\_centres})   			
   			\State Create references datasets
   			\For{each references dataset}
			\State cluster\_centres, clusters =  \Call{Kmeans}{data, k, cutoff}
  			\State $BWk = \log$(\Call{Wk}{clusters, cluster\_centres})
   			\EndFor   
   			\State $Wkb = \frac{\sum(BWk)}{10} $	
   			\State $sk = \sqrt{\sum(\frac{(BWk - Wkb)^2}{10})}$	
    	\EndFor
    \State $sk = sk \times \sqrt{1+\frac{1}{B}}$
    \State \Return ks, Wk, Wkb, sk, data\_centres, clusters
    \EndFunction
    \Statex
	\Function{Distance}{data, cutoff}
		    \State ks, logWks, logWkbs, sk, clusters\_means, clusts = \Call{gap\_statistic}{data, cutoff}
		    \State gaps = logWks $-$ logWkbs
		    \State optimum number of clusters = $gaps[i] \geq (gaps[i+1]-sk[i+1])$
	\State \Return cluster\_counter, clusters\_means
	\EndFunction
  \end{algorithmic}
\end{algorithm}
\clearpage



\section{K-means clustering}
\begin{algorithm}
\label{alg:KMeans}
\caption{Clustering stochastic case}
 \begin{algorithmic}[1]
    \Statex
    
    
    \Function{K\-means clustering}{data, k, cutoff}
    	\Statex
    	\Function{Update\_centres}{old\_centres, values}
    		\State centre\_coords =  mean for each dimension
    		\State shift = \Call{getDistance}{centre\_coords, old\_centres}
    		\State \Return shift, centre\_coords
    	\EndFunction
    
    	\Statex
    	\Function{getDistance}{$a, b$}
    		\State $dist = \sqrt{(a[x] - b[x])^2+(a[y] - b[y])^2}$
    		\State \Return $dist$
    	\EndFunction
      
      	\Statex
      	\While{True}
      		\For{each point in data}
      			\For{each cluster}
      				\State $dist = $\Call{getDistance}{point, cluster centre}
      			\EndFor
      			\State Find cluster with minimum distance
      			\State Repopulate clusters
      		\EndFor
      		
      		\Let{biggest\_shift}{0}
      		\For{as many times as there are clusters}
      			\State shift, cluster centres $=$ \Call{Update\_centres}{old\_centres, clusters}
      			\State biggest\_shift =  max between shift, biggest\_shift
      			
      		\EndFor
      		\If{biggest\_shift $\leq$ cutoff}
      			\State break
      		\EndIf
      	\EndWhile
      \State \Return cluster\_centres, clusters
    \EndFunction

  \end{algorithmic}
\end{algorithm}

\section{Two sample Kolmogorov-Smirnov test in 2D}
The following code is adapted from~\autocite{Syrtis2016}. 

\begin{lstlisting}
from __future__ import division
import numpy as np
from numpy import random
from scipy.spatial.distance import pdist, cdist
from scipy.stats import kstwobign, pearsonr
from scipy.stats import genextreme

__all__ = ['ks2d2s', 'estat']

def ks2d2s(x1, y1, x2, y2, nboot=None, extra=False):


    '''Two-dimensional Kolmogorov-Smirnov test on two samples.
    Parameters
    ----------
    x1, y1 : ndarray, shape (n1, )
        Data of sample 1.
    x2, y2 : ndarray, shape (n2, )
        Data of sample 2. Size of two samples can be different.
    extra: bool, optional
        If True, KS statistic is also returned. Default is False.
    Returns
    -------
    D : float, optional
        KS statistic. Returned if keyword `extra` is True.
	"""

    assert (len(x1) == len(y1)) and (len(x2) == len(y2))
    n1, n2 = len(x1), len(x2)
    sqen = np.sqrt(n1*n2/(n1+n2))

    D1 = maxdist(x1, y1, x2, y2)
    D2 = maxdist(x2, y2, x1, y1)
    D = (D1 + D2)/2

    r1 = pearsonr(x1, y1)[0]
    r2 = pearsonr(x2, y2)[0]

    if np.isfinite(r2) == False:
        r2 = 0
    r = np.sqrt(1 - (r1**2 + r2**2)/2)

    if nboot is None:
        D = D * sqen/(1 + r*(0.25 - 0.75/sqen))
        #p = kstwobign.sf(D)
        p = 0
    else:
        raise NotImplementedError
    if extra:
        return p, D
    else:
        return p


def maxdist(x1, y1, x2, y2):
    n1 = len(x1)
    D1 = np.zeros((n1, 4))
    for i in range(n1):
        a1, b1, c1, d1 = quadct(x1[i], y1[i], x1, y1)
        a2, b2, c2, d2 = quadct(x1[i], y1[i], x2, y2)
        D1[i] = [a1-a2, b1-b2, c1-c2, d1-d2]
    D1[:,0] -= 1/n1         # re-assign the point to maximize difference, the
    #D1[D1 >= 0] += 1/n1     # discrepancy is significant for N < ~50
    #D1 = np.abs(D1).max()
    ix = np.unravel_index(np.argmax(np.abs(D1)), D1.shape)
    D1 = D1[ix]
    if D1 >=0:
        D1 += 1/n1
    return D1


def quadct(x, y, xx, yy):
    n = len(xx)
    ix1, ix2 = xx <= x, yy <= y
    a = np.sum( ix1 &  ix2)/n
    b = np.sum( ix1 & ~ix2)/n
    c = np.sum(~ix1 &  ix2)/n
    d = 1 - a - b -c
    return a, b, c, d

\end{lstlisting}



